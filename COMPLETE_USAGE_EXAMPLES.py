"""
VCC GPUåŠ é€Ÿå™¨ - å®Œæ•´è°ƒç”¨ç¤ºä¾‹é›†åˆ
æ¶µç›–å„ç§çœŸå®ä½¿ç”¨åœºæ™¯çš„å…·ä½“ä»£ç ç¤ºä¾‹
"""

import os
import time
import torch
import numpy as np
import anndata as ad
import polars as pl
from pathlib import Path


# =============================================================================
# ç¤ºä¾‹1: æœ€åŸºç¡€çš„ä½¿ç”¨ - ç›´æ¥æ›¿æ¢ç°æœ‰ä»£ç 
# =============================================================================

def example_1_basic_replacement():
    """
    åœºæ™¯ï¼šæ‚¨ç°åœ¨æœ‰ä½¿ç”¨å®˜æ–¹cell-evalçš„ä»£ç ï¼Œæƒ³è¦GPUåŠ é€Ÿ
    """
    print("=== ç¤ºä¾‹1: åŸºç¡€æ›¿æ¢ä½¿ç”¨ ===")
    
    # ---------- åŸå§‹ä»£ç  (CPUç‰ˆæœ¬) ----------
    print("1. åŸå§‹CPUç‰ˆæœ¬ä»£ç :")
    print("""
    # æ‚¨çš„åŸå§‹ä»£ç å¯èƒ½é•¿è¿™æ ·:
    from cell_eval import MetricsEvaluator
    
    evaluator = MetricsEvaluator(
        adata_pred="predictions.h5ad",
        adata_real="ground_truth.h5ad", 
        control_pert="non-targeting",
        pert_col="target"
    )
    results, agg = evaluator.compute(profile="vcc")
    """)
    
    # ---------- GPUåŠ é€Ÿç‰ˆæœ¬ (åªæ”¹2è¡Œ!) ----------
    print("2. GPUåŠ é€Ÿç‰ˆæœ¬ (åªéœ€ä¿®æ”¹2è¡Œ):")
    print("""
    # ä¿®æ”¹ç¬¬1è¡Œ: å¯¼å…¥GPUç‰ˆæœ¬
    from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
    
    # ä¿®æ”¹ç¬¬2è¡Œ: ä½¿ç”¨GPU evaluator + æ·»åŠ GPUå‚æ•°
    evaluator = AcceleratedMetricsEvaluator(
        adata_pred="predictions.h5ad",
        adata_real="ground_truth.h5ad",
        control_pert="non-targeting", 
        pert_col="target",
        enable_gpu_acceleration=True  # æ–°å¢è¿™ä¸€è¡Œ
    )
    results, agg = evaluator.compute(profile="vcc")  # å…¶ä½™å®Œå…¨ç›¸åŒ
    """)
    
    # å®é™…è¿è¡Œç¤ºä¾‹ (ä½¿ç”¨æµ‹è¯•æ•°æ®)
    print("3. å®é™…è¿è¡ŒGPUç‰ˆæœ¬:")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    from cell_eval.data import build_random_anndata
    test_pred = build_random_anndata(n_cells=1000, n_genes=5000, n_perts=50, 
                                    pert_col="target", control_var="non-targeting")
    test_real = build_random_anndata(n_cells=1000, n_genes=5000, n_perts=50,
                                    pert_col="target", control_var="non-targeting")
    
    # GPUåŠ é€Ÿè¯„ä¼°
    from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
    
    start_time = time.time()
    evaluator = AcceleratedMetricsEvaluator(
        adata_pred=test_pred,
        adata_real=test_real,
        control_pert="non-targeting",
        pert_col="target", 
        enable_gpu_acceleration=True
    )
    results, agg = evaluator.compute(profile="vcc")
    gpu_time = time.time() - start_time
    
    print(f"   GPUè¯„åˆ†å®Œæˆ: {gpu_time:.3f}ç§’")
    print(f"   ç»“æœç»´åº¦: {results.shape}")
    print()


# =============================================================================
# ç¤ºä¾‹2: VCCæ¯”èµ›å®Œæ•´æµç¨‹
# =============================================================================

def example_2_vcc_competition_workflow():
    """
    åœºæ™¯ï¼šå®Œæ•´çš„VCCæ¯”èµ›è¯„åˆ†æµç¨‹
    """
    print("=== ç¤ºä¾‹2: VCCæ¯”èµ›å®Œæ•´æµç¨‹ ===")
    
    # æ­¥éª¤1: å‡†å¤‡æ•°æ®æ–‡ä»¶è·¯å¾„
    print("æ­¥éª¤1: æ•°æ®å‡†å¤‡")
    
    # æ¨¡æ‹Ÿæ‚¨çš„å®é™…æ–‡ä»¶è·¯å¾„
    your_prediction_file = "your_model_predictions.h5ad"   # æ‚¨çš„æ¨¡å‹è¾“å‡º
    vcc_test_data_file = "vcc_test_ground_truth.h5ad"     # VCCæµ‹è¯•é›†çœŸå€¼
    baseline_predictions = "vcc_baseline_predictions.h5ad" # VCC baseline
    
    # å¯¹äºæ¼”ç¤ºï¼Œæˆ‘ä»¬ç”Ÿæˆæµ‹è¯•æ•°æ®
    print("   ç”ŸæˆVCCè§„æ¨¡æµ‹è¯•æ•°æ® (150æ‰°åŠ¨, 20000åŸºå› )...")
    vcc_test_data = build_random_anndata(
        n_cells=3000, n_genes=20000, n_perts=150,
        pert_col="target", control_var="non-targeting"
    )
    your_predictions = build_random_anndata(
        n_cells=3000, n_genes=20000, n_perts=150, 
        pert_col="target", control_var="non-targeting"
    )
    
    # æ­¥éª¤2: è¯„ä¼°æ‚¨çš„æ¨¡å‹ç›¸å¯¹äºæµ‹è¯•é›†
    print("æ­¥éª¤2: è¯„ä¼°æ¨¡å‹æ€§èƒ½")
    
    from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
    
    model_evaluator = AcceleratedMetricsEvaluator(
        adata_pred=your_predictions,        # æ‚¨çš„æ¨¡å‹é¢„æµ‹
        adata_real=vcc_test_data,          # VCCæµ‹è¯•é›†çœŸå€¼  
        control_pert="non-targeting",       # VCCæ ‡å‡†å¯¹ç…§ç»„
        pert_col="target",                 # VCCæ ‡å‡†æ‰°åŠ¨åˆ—
        enable_gpu_acceleration=True,
        outdir="./vcc_model_evaluation"
    )
    
    print("   æ­£åœ¨GPUåŠ é€Ÿè®¡ç®—VCCæŒ‡æ ‡...")
    start_time = time.time()
    model_results, model_agg = model_evaluator.compute(profile="vcc")
    eval_time = time.time() - start_time
    
    print(f"   æ¨¡å‹è¯„ä¼°å®Œæˆ: {eval_time:.2f}ç§’")
    
    # æ­¥éª¤3: è®¡ç®—baselineåˆ†æ•° (ç”¨äºæ ‡å‡†åŒ–)
    print("æ­¥éª¤3: è®¡ç®—baselineåˆ†æ•°")
    
    # å¦‚æœæ‚¨éœ€è¦è®¡ç®—baseline
    from cell_eval import build_base_mean_adata
    
    baseline_data = build_base_mean_adata(
        adata=vcc_test_data,  # ä½¿ç”¨è®­ç»ƒæ•°æ®æ„å»ºbaseline
        control_pert="non-targeting",
        pert_col="target"
    )
    
    baseline_evaluator = AcceleratedMetricsEvaluator(
        adata_pred=baseline_data,
        adata_real=vcc_test_data,
        control_pert="non-targeting", 
        pert_col="target",
        enable_gpu_acceleration=True,
        outdir="./vcc_baseline_evaluation"
    )
    
    baseline_results, baseline_agg = baseline_evaluator.compute(profile="vcc")
    print("   baselineè¯„ä¼°å®Œæˆ")
    
    # æ­¥éª¤4: è®¡ç®—ç›¸å¯¹äºbaselineçš„æ ‡å‡†åŒ–åˆ†æ•°
    print("æ­¥éª¤4: è®¡ç®—VCCæœ€ç»ˆåˆ†æ•°")
    
    from cell_eval import score_agg_metrics
    
    # ä¿å­˜ä¸­é—´ç»“æœ
    model_agg.write_csv("./vcc_model_agg.csv")
    baseline_agg.write_csv("./vcc_baseline_agg.csv")
    
    # è®¡ç®—æ ‡å‡†åŒ–åˆ†æ•°
    final_scores = score_agg_metrics(
        results_user="./vcc_model_agg.csv",
        results_base="./vcc_baseline_agg.csv", 
        output="./vcc_final_scores.csv"
    )
    
    # æå–æœ€ç»ˆVCCåˆ†æ•°
    avg_score_row = final_scores.filter(pl.col("metric") == "avg_score")
    if len(avg_score_row) > 0:
        final_vcc_score = avg_score_row["from_baseline"][0]
        print(f"   ğŸ† æ‚¨çš„VCCæœ€ç»ˆåˆ†æ•°: {final_vcc_score:.4f}")
        
        if final_vcc_score > 0.1:
            print("   ğŸš€ ä¼˜ç§€ï¼æ˜¾è‘—è¶…è¶Šbaseline")
        elif final_vcc_score > 0:
            print("   âœ¨ è‰¯å¥½ï¼è¶…è¶Šbaseline")
        else:
            print("   ğŸ“ˆ éœ€è¦æ”¹è¿›ï¼Œæœªè¶…è¶Šbaseline")
    
    print()


# =============================================================================
# ç¤ºä¾‹3: æ‰¹é‡æ¨¡å‹å¯¹æ¯”
# =============================================================================

def example_3_batch_model_comparison():
    """
    åœºæ™¯ï¼šæ‚¨æœ‰å¤šä¸ªæ¨¡å‹ç‰ˆæœ¬ï¼Œæƒ³æ‰¹é‡å¯¹æ¯”æ€§èƒ½
    """
    print("=== ç¤ºä¾‹3: æ‰¹é‡æ¨¡å‹å¯¹æ¯” ===")
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    print("å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...")
    ground_truth = build_random_anndata(
        n_cells=2000, n_genes=10000, n_perts=100,
        pert_col="target", control_var="non-targeting"
    )
    
    # æ¨¡æ‹Ÿå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    model_names = ["ModelV1", "ModelV2", "ModelV3", "Baseline"]
    model_predictions = {}
    
    for model_name in model_names:
        # æ¨¡æ‹Ÿä¸åŒè´¨é‡çš„é¢„æµ‹ç»“æœ
        noise_level = {"ModelV1": 0.2, "ModelV2": 0.15, "ModelV3": 0.1, "Baseline": 0.3}
        
        pred_data = build_random_anndata(
            n_cells=2000, n_genes=10000, n_perts=100,
            pert_col="target", control_var="non-targeting"
        )
        model_predictions[model_name] = pred_data
    
    # æ‰¹é‡è¯„ä¼°æ‰€æœ‰æ¨¡å‹
    print("æ‰¹é‡è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    
    from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
    
    model_scores = {}
    
    for model_name, pred_data in model_predictions.items():
        print(f"   è¯„ä¼° {model_name}...")
        
        evaluator = AcceleratedMetricsEvaluator(
            adata_pred=pred_data,
            adata_real=ground_truth,
            control_pert="non-targeting",
            pert_col="target",
            enable_gpu_acceleration=True,
            outdir=f"./batch_eval_{model_name.lower()}"
        )
        
        start_time = time.time()
        results, agg = evaluator.compute(profile="vcc")
        eval_time = time.time() - start_time
        
        # æå–å…³é”®æŒ‡æ ‡ (ç®€åŒ–ç‰ˆæœ¬)
        model_scores[model_name] = {
            "eval_time": eval_time,
            "results_shape": results.shape,
            "agg_shape": agg.shape
        }
        
        print(f"      å®Œæˆï¼Œè€—æ—¶: {eval_time:.2f}ç§’")
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print("\n=== æ¨¡å‹å¯¹æ¯”ç»“æœ ===")
    print(f"{'æ¨¡å‹åç§°':<10} {'è¯„ä¼°æ—¶é—´':<10} {'ç»“æœç»´åº¦':<15}")
    print("-" * 35)
    
    for model_name, scores in model_scores.items():
        print(f"{model_name:<10} {scores['eval_time']:<10.2f} {str(scores['results_shape']):<15}")
    
    print()


# =============================================================================
# ç¤ºä¾‹4: è‡ªå®šä¹‰å‚æ•°å’Œé«˜çº§é…ç½®
# =============================================================================

def example_4_advanced_configuration():
    """
    åœºæ™¯ï¼šéœ€è¦è‡ªå®šä¹‰å‚æ•°å’Œé«˜çº§é…ç½®
    """
    print("=== ç¤ºä¾‹4: é«˜çº§é…ç½® ===")
    
    # å‡†å¤‡æ•°æ®
    test_data = build_random_anndata(n_cells=1500, n_genes=8000, n_perts=75)
    pred_data = build_random_anndata(n_cells=1500, n_genes=8000, n_perts=75)
    
    from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
    
    # 1. å®Œæ•´å‚æ•°é…ç½®
    print("1. å®Œæ•´å‚æ•°é…ç½®ç¤ºä¾‹:")
    
    evaluator = AcceleratedMetricsEvaluator(
        # æ•°æ®å‚æ•°
        adata_pred=pred_data,
        adata_real=test_data,
        control_pert="control",        # æ‚¨çš„å¯¹ç…§ç»„åç§°
        pert_col="perturbation",       # æ‚¨çš„æ‰°åŠ¨åˆ—åç§°
        
        # GPUåŠ é€Ÿå‚æ•°
        enable_gpu_acceleration=True,  # å¯ç”¨GPU
        gpu_device="cuda:0",          # æŒ‡å®šGPUè®¾å¤‡ 
        fallback_to_cpu=True,         # GPUå¤±è´¥æ—¶è‡ªåŠ¨å›é€€
        
        # è¾“å‡ºå‚æ•°
        outdir="./advanced_eval_results",
        
        # å®˜æ–¹cell-evalå‚æ•° (é€ä¼ )
        allow_discrete=False,
        num_threads=8,
        
        # DEè®¡ç®—å‚æ•° (å¦‚æœéœ€è¦)
        de_pred=None,  # å¯ä»¥æä¾›é¢„è®¡ç®—çš„DEç»“æœ
        de_real=None   # å¯ä»¥æä¾›é¢„è®¡ç®—çš„DEç»“æœ
    )
    
    # 2. è·å–ç³»ç»Ÿä¿¡æ¯
    print("2. ç³»ç»Ÿé…ç½®ä¿¡æ¯:")
    sys_info = evaluator.get_acceleration_info()
    for key, value in sys_info.items():
        print(f"   {key}: {value}")
    
    # 3. è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°
    print("3. è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°:")
    results, agg = evaluator.compute(
        profile="vcc",                # VCCæŒ‡æ ‡é›†
        use_gpu_for_vcc=True,        # å¯¹VCCæŒ‡æ ‡ä½¿ç”¨GPU
        write_csv=True,              # ä¿å­˜CSVç»“æœ
        break_on_error=False         # é‡åˆ°é”™è¯¯ç»§ç»­æ‰§è¡Œ
    )
    
    print(f"   è‡ªå®šä¹‰è¯„ä¼°å®Œæˆ: {results.shape}")
    
    # 4. æ€§èƒ½åŸºå‡†æµ‹è¯•
    print("4. æ€§èƒ½åŸºå‡†æµ‹è¯•:")
    benchmark = evaluator.benchmark_acceleration(
        n_perts=100, n_genes=10000, num_runs=3
    )
    
    if "error" not in benchmark:
        print(f"   CPUå¹³å‡æ—¶é—´: {benchmark['cpu_time_avg']:.3f}s")
        print(f"   GPUå¹³å‡æ—¶é—´: {benchmark['gpu_time_avg']:.3f}s") 
        print(f"   åŠ é€Ÿæ¯”: {benchmark['speedup']:.1f}x")
    
    print()


# =============================================================================
# ç¤ºä¾‹5: é”™è¯¯å¤„ç†å’Œè°ƒè¯•
# =============================================================================

def example_5_error_handling_and_debugging():
    """
    åœºæ™¯ï¼šå¤„ç†å„ç§å¯èƒ½çš„é”™è¯¯å’Œè°ƒè¯•é—®é¢˜
    """
    print("=== ç¤ºä¾‹5: é”™è¯¯å¤„ç†å’Œè°ƒè¯• ===")
    
    # 1. ç¯å¢ƒæ£€æŸ¥
    print("1. ç¯å¢ƒæ£€æŸ¥:")
    
    # æ£€æŸ¥PyTorchå’ŒCUDA
    print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
        print(f"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
        print(f"   å½“å‰å†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1e6:.1f}MB")
    
    # æ£€æŸ¥æ¨¡å—å¯¼å…¥
    try:
        from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
        print("   âœ… GPUåŠ é€Ÿæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"   âŒ GPUåŠ é€Ÿæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print("   è¯·æ£€æŸ¥vcc_gpu_acceleratoræ–‡ä»¶å¤¹æ˜¯å¦åœ¨æ­£ç¡®ä½ç½®")
        return
    
    # 2. å®‰å…¨çš„evaluatoråˆ›å»º
    print("2. å®‰å…¨çš„evaluatoråˆ›å»º:")
    
    try:
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_real = build_random_anndata(n_cells=500, n_genes=2000, n_perts=20)
        test_pred = build_random_anndata(n_cells=500, n_genes=2000, n_perts=20)
        
        # åˆ›å»ºevaluator withé”™è¯¯å¤„ç†
        evaluator = AcceleratedMetricsEvaluator(
            adata_pred=test_pred,
            adata_real=test_real,
            control_pert="control", 
            pert_col="perturbation",
            enable_gpu_acceleration=True,
            fallback_to_cpu=True  # é‡è¦ï¼šå¯ç”¨è‡ªåŠ¨å›é€€
        )
        
        print("   âœ… Evaluatoråˆ›å»ºæˆåŠŸ")
        
        # è·å–è¯¦ç»†é…ç½®ä¿¡æ¯
        config = evaluator.get_acceleration_info()
        print(f"   GPUå¯ç”¨: {config['gpu_available']}")
        
    except Exception as e:
        print(f"   âŒ Evaluatoråˆ›å»ºå¤±è´¥: {e}")
        print("   è¯·æ£€æŸ¥æ•°æ®æ ¼å¼å’Œå‚æ•°é…ç½®")
        return
    
    # 3. å®‰å…¨çš„è®¡ç®—æ‰§è¡Œ
    print("3. å®‰å…¨çš„è®¡ç®—æ‰§è¡Œ:")
    
    try:
        start_time = time.time()
        results, agg = evaluator.compute(profile="vcc")
        compute_time = time.time() - start_time
        
        print(f"   âœ… è®¡ç®—æˆåŠŸå®Œæˆ: {compute_time:.3f}ç§’")
        print(f"   ç»“æœç»´åº¦: {results.shape}")
        
    except torch.cuda.OutOfMemoryError:
        print("   âš ï¸ GPUå†…å­˜ä¸è¶³ï¼Œå°è¯•å‡å°‘æ•°æ®è§„æ¨¡æˆ–ä½¿ç”¨CPU")
        
        # è‡ªåŠ¨å›é€€åˆ°CPUæ¨¡å¼
        evaluator_cpu = AcceleratedMetricsEvaluator(
            adata_pred=test_pred,
            adata_real=test_real,
            control_pert="control",
            pert_col="perturbation", 
            enable_gpu_acceleration=False  # å¼ºåˆ¶CPUæ¨¡å¼
        )
        
        results, agg = evaluator_cpu.compute(profile="vcc")
        print("   âœ… CPUæ¨¡å¼è®¡ç®—å®Œæˆ")
        
    except Exception as e:
        print(f"   âŒ è®¡ç®—å¤±è´¥: {e}")
        print("   è¯·æ£€æŸ¥æ•°æ®å…¼å®¹æ€§å’Œç³»ç»Ÿé…ç½®")
    
    # 4. å†…å­˜ä½¿ç”¨ç›‘æ§
    print("4. å†…å­˜ä½¿ç”¨ç›‘æ§:")
    
    if torch.cuda.is_available():
        # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        allocated = torch.cuda.memory_allocated() / 1e6
        cached = torch.cuda.memory_reserved() / 1e6
        total = torch.cuda.get_device_properties(0).total_memory / 1e6
        
        print(f"   GPUå†…å­˜å·²åˆ†é…: {allocated:.1f}MB")
        print(f"   GPUå†…å­˜ç¼“å­˜: {cached:.1f}MB") 
        print(f"   GPUå†…å­˜æ€»è®¡: {total:.1f}MB")
        print(f"   ä½¿ç”¨ç‡: {(allocated/total)*100:.1f}%")
        
        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        print("   ğŸ§¹ GPUå†…å­˜å·²æ¸…ç†")
    
    print()


# =============================================================================
# ç¤ºä¾‹6: ä¸ç°æœ‰ä»£ç åº“é›†æˆ
# =============================================================================

def example_6_integration_with_existing_codebase():
    """
    åœºæ™¯ï¼šä¸ç°æœ‰ä»£ç åº“é›†æˆçš„å…·ä½“æ–¹æ³•
    """
    print("=== ç¤ºä¾‹6: ä»£ç åº“é›†æˆ ===")
    
    # 1. ç°æœ‰å‡½æ•°çš„åŒ…è£…
    print("1. åŒ…è£…ç°æœ‰è¯„ä¼°å‡½æ•°:")
    
    def original_vcc_evaluation_function(pred_file, real_file, output_dir):
        """
        è¿™æ˜¯æ‚¨ç°æœ‰çš„VCCè¯„ä¼°å‡½æ•° (ç¤ºä¾‹)
        """
        # åŸå§‹å®ç° (CPUç‰ˆæœ¬)
        from cell_eval import MetricsEvaluator
        
        evaluator = MetricsEvaluator(
            adata_pred=pred_file,
            adata_real=real_file,
            control_pert="non-targeting",
            pert_col="target",
            outdir=output_dir
        )
        
        return evaluator.compute(profile="vcc")
    
    def gpu_accelerated_vcc_evaluation_function(pred_file, real_file, output_dir, use_gpu=True):
        """
        GPUåŠ é€Ÿç‰ˆæœ¬ - åŒ…è£…æ‚¨çš„ç°æœ‰å‡½æ•°
        """
        if use_gpu:
            from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
            
            evaluator = AcceleratedMetricsEvaluator(
                adata_pred=pred_file,
                adata_real=real_file,
                control_pert="non-targeting",
                pert_col="target", 
                outdir=output_dir,
                enable_gpu_acceleration=True,
                fallback_to_cpu=True
            )
        else:
            # å›é€€åˆ°åŸå§‹å®ç°
            from cell_eval import MetricsEvaluator
            
            evaluator = MetricsEvaluator(
                adata_pred=pred_file,
                adata_real=real_file,
                control_pert="non-targeting",
                pert_col="target",
                outdir=output_dir
            )
        
        return evaluator.compute(profile="vcc")
    
    # 2. ç±»çš„ç»§æ‰¿æ‰©å±•
    print("2. ç±»çš„ç»§æ‰¿æ‰©å±•:")
    
    class MyVCCEvaluator:
        """æ‚¨ç°æœ‰çš„è¯„ä¼°ç±»"""
        
        def __init__(self, config):
            self.config = config
            
        def evaluate_model(self, model_predictions):
            # æ‚¨çš„ç°æœ‰é€»è¾‘
            pass
    
    class GPUAcceleratedVCCEvaluator(MyVCCEvaluator):
        """GPUåŠ é€Ÿæ‰©å±•ç‰ˆæœ¬"""
        
        def __init__(self, config, enable_gpu=True):
            super().__init__(config)
            self.enable_gpu = enable_gpu
            
        def evaluate_model(self, model_predictions):
            if self.enable_gpu:
                return self._gpu_evaluate(model_predictions)
            else:
                return super().evaluate_model(model_predictions)
                
        def _gpu_evaluate(self, model_predictions):
            from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
            
            evaluator = AcceleratedMetricsEvaluator(
                adata_pred=model_predictions,
                adata_real=self.config['ground_truth'],
                control_pert=self.config['control_pert'],
                pert_col=self.config['pert_col'],
                enable_gpu_acceleration=True
            )
            
            return evaluator.compute(profile="vcc")
    
    # 3. é…ç½®æ–‡ä»¶é©±åŠ¨çš„é›†æˆ
    print("3. é…ç½®é©±åŠ¨é›†æˆ:")
    
    def load_evaluation_config():
        """åŠ è½½è¯„ä¼°é…ç½®"""
        return {
            "data": {
                "pred_file": "model_predictions.h5ad",
                "real_file": "ground_truth.h5ad", 
                "control_pert": "non-targeting",
                "pert_col": "target"
            },
            "compute": {
                "use_gpu": True,
                "gpu_device": "cuda:0", 
                "fallback_to_cpu": True,
                "profile": "vcc"
            },
            "output": {
                "dir": "./gpu_eval_results",
                "save_csv": True
            }
        }
    
    def run_configured_evaluation(config):
        """åŸºäºé…ç½®è¿è¡Œè¯„ä¼°"""
        
        if config["compute"]["use_gpu"]:
            from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
            
            evaluator = AcceleratedMetricsEvaluator(
                adata_pred=config["data"]["pred_file"],
                adata_real=config["data"]["real_file"],
                control_pert=config["data"]["control_pert"],
                pert_col=config["data"]["pert_col"],
                enable_gpu_acceleration=config["compute"]["use_gpu"],
                gpu_device=config["compute"]["gpu_device"],
                fallback_to_cpu=config["compute"]["fallback_to_cpu"],
                outdir=config["output"]["dir"]
            )
        else:
            from cell_eval import MetricsEvaluator
            
            evaluator = MetricsEvaluator(
                adata_pred=config["data"]["pred_file"],
                adata_real=config["data"]["real_file"],
                control_pert=config["data"]["control_pert"],
                pert_col=config["data"]["pert_col"],
                outdir=config["output"]["dir"]
            )
        
        return evaluator.compute(
            profile=config["compute"]["profile"],
            write_csv=config["output"]["save_csv"]
        )
    
    # æ¼”ç¤ºé…ç½®é©±åŠ¨çš„ä½¿ç”¨
    print("   é…ç½®é©±åŠ¨è¯„ä¼°ç¤ºä¾‹:")
    config = load_evaluation_config()
    print(f"   GPUæ¨¡å¼: {config['compute']['use_gpu']}")
    print(f"   è¾“å‡ºç›®å½•: {config['output']['dir']}")
    
    print()


# =============================================================================
# ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
# =============================================================================

def main():
    """è¿è¡Œæ‰€æœ‰å®Œæ•´ç¤ºä¾‹"""
    print("VCC GPUåŠ é€Ÿå™¨ - å®Œæ•´ä½¿ç”¨ç¤ºä¾‹é›†åˆ")
    print("=" * 60)
    
    # æ£€æŸ¥åŸºç¡€ç¯å¢ƒ
    print(f"ç¯å¢ƒæ£€æŸ¥:")
    print(f"   Pythonç‰ˆæœ¬: {os.sys.version.split()[0]}")
    print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name()}")
    print()
    
    # å¯¼å…¥æ£€æŸ¥
    try:
        from vcc_gpu_accelerator import AcceleratedMetricsEvaluator
        print("âœ… GPUåŠ é€Ÿæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError:
        print("âŒ GPUåŠ é€Ÿæ¨¡å—å¯¼å…¥å¤±è´¥")
        print("è¯·ç¡®ä¿vcc_gpu_accelerator/æ–‡ä»¶å¤¹åœ¨æ­£ç¡®ä½ç½®")
        return
    
    from cell_eval.data import build_random_anndata
    print("âœ… æµ‹è¯•æ•°æ®ç”Ÿæˆæ¨¡å—å¯ç”¨")
    print()
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    try:
        example_1_basic_replacement()
        example_2_vcc_competition_workflow() 
        example_3_batch_model_comparison()
        example_4_advanced_configuration()
        example_5_error_handling_and_debugging()
        example_6_integration_with_existing_codebase()
        
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print("1. å¯¹äºæ—¥å¸¸ä½¿ç”¨ï¼Œæ¨èç¤ºä¾‹1çš„ç®€å•æ›¿æ¢æ–¹æ³•")
        print("2. å¯¹äºVCCæ¯”èµ›ï¼Œå‚è€ƒç¤ºä¾‹2çš„å®Œæ•´æµç¨‹")  
        print("3. å¯¹äºæ‰¹é‡è¯„ä¼°ï¼Œå‚è€ƒç¤ºä¾‹3çš„æ‰¹å¤„ç†æ–¹æ³•")
        print("4. é‡åˆ°é—®é¢˜æ—¶ï¼Œå‚è€ƒç¤ºä¾‹5çš„è°ƒè¯•æ–¹æ³•")
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹è¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ç¯å¢ƒé…ç½®å’Œä¾èµ–å®‰è£…")


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«ä»¥æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
    import logging
    logging.basicConfig(level=logging.INFO)
    
    main()