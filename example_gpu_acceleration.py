"""
VCC GPUåŠ é€Ÿä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¼‚æ„åŠ é€Ÿæ¨¡å—æå‡VCCè¯„åˆ†é€Ÿåº¦
"""

import numpy as np
import torch
import time
from pathlib import Path

# å¯¼å…¥å®˜æ–¹cell-eval (ä¸ä¿®æ”¹)
from cell_eval import MetricsEvaluator
from cell_eval.data import build_random_anndata

# å¯¼å…¥æˆ‘ä»¬çš„GPUåŠ é€Ÿæ¨¡å— (å®Œå…¨ç‹¬ç«‹)
from vcc_gpu_accelerator import AcceleratedMetricsEvaluator, HybridVCCEvaluator
from vcc_gpu_accelerator.utils import format_benchmark_results, memory_usage_estimate


def example_1_basic_usage():
    """ç¤ºä¾‹1: åŸºç¡€ä½¿ç”¨ - ç›´æ¥æ›¿æ¢å®˜æ–¹evaluator"""
    print("=== ç¤ºä¾‹1: åŸºç¡€GPUåŠ é€Ÿä½¿ç”¨ ===\n")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    print("ç”Ÿæˆæµ‹è¯•æ•°æ®...")
    adata_real = build_random_anndata(n_cells=2000, n_genes=5000, n_perts=50)
    adata_pred = build_random_anndata(n_cells=2000, n_genes=5000, n_perts=50)
    
    # æ–¹å¼1: åŸå§‹CPUç‰ˆæœ¬
    print("1. ä½¿ç”¨åŸå§‹CPUç‰ˆæœ¬:")
    start_time = time.time()
    cpu_evaluator = MetricsEvaluator(
        adata_pred=adata_pred,
        adata_real=adata_real,
        control_pert="control", 
        pert_col="perturbation"
    )
    cpu_results, cpu_agg = cpu_evaluator.compute(profile="vcc")
    cpu_time = time.time() - start_time
    print(f"   CPUæ—¶é—´: {cpu_time:.3f}ç§’")
    
    # æ–¹å¼2: GPUåŠ é€Ÿç‰ˆæœ¬ (APIå®Œå…¨å…¼å®¹)
    print("2. ä½¿ç”¨GPUåŠ é€Ÿç‰ˆæœ¬:")
    start_time = time.time()
    gpu_evaluator = AcceleratedMetricsEvaluator(  # å”¯ä¸€çš„æ”¹åŠ¨ï¼šç±»å
        adata_pred=adata_pred,
        adata_real=adata_real,
        control_pert="control",
        pert_col="perturbation",
        enable_gpu_acceleration=True  # å¯ç”¨GPUåŠ é€Ÿ
    )
    gpu_results, gpu_agg = gpu_evaluator.compute(profile="vcc")
    gpu_time = time.time() - start_time
    print(f"   GPUæ—¶é—´: {gpu_time:.3f}ç§’")
    print(f"   åŠ é€Ÿæ¯”: {cpu_time/gpu_time:.1f}x\n")
    
    # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
    print("GPUåŠ é€Ÿå™¨ä¿¡æ¯:")
    info = gpu_evaluator.get_acceleration_info()
    for key, value in info.items():
        print(f"   {key}: {value}")
    print()


def example_2_benchmark():
    """ç¤ºä¾‹2: æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("=== ç¤ºä¾‹2: æ€§èƒ½åŸºå‡†æµ‹è¯• ===\n")
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œè·³è¿‡GPUåŸºå‡†æµ‹è¯•")
        return
    
    # åˆ›å»ºåŠ é€Ÿevaluator
    dummy_data = build_random_anndata(n_cells=100, n_genes=100, n_perts=10)
    evaluator = AcceleratedMetricsEvaluator(
        adata_pred=dummy_data,
        adata_real=dummy_data,
        control_pert="control",
        pert_col="perturbation"
    )
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯• (ä¸åŒæ•°æ®è§„æ¨¡)
    test_cases = [
        {"n_perts": 50, "n_genes": 10000, "desc": "å°è§„æ¨¡æµ‹è¯•"},
        {"n_perts": 150, "n_genes": 20000, "desc": "VCCçœŸå®è§„æ¨¡"},
        {"n_perts": 300, "n_genes": 20000, "desc": "å¤§è§„æ¨¡æµ‹è¯•"}
    ]
    
    for case in test_cases:
        print(f"è¿è¡Œ {case['desc']} ({case['n_perts']} æ‰°åŠ¨, {case['n_genes']} åŸºå› )...")
        
        # å†…å­˜ä¼°ç®—
        memory_info = memory_usage_estimate(case['n_perts'], case['n_genes'])
        print(f"   é¢„è®¡GPUå†…å­˜éœ€æ±‚: {memory_info['total_estimated_mb']:.1f}MB")
        print(f"   {memory_info['recommendation']}")
        
        # æ€§èƒ½æµ‹è¯•
        benchmark_results = evaluator.benchmark_acceleration(
            n_perts=case['n_perts'], 
            n_genes=case['n_genes'],
            num_runs=3
        )
        
        if "error" not in benchmark_results:
            speedup = benchmark_results.get('speedup', 0)
            print(f"   åŠ é€Ÿæ¯”: {speedup:.1f}x")
            if speedup > 5:
                print("   âœ… æ˜¾è‘—åŠ é€Ÿ!")
            elif speedup > 2:
                print("   âœ¨ é€‚åº¦åŠ é€Ÿ")
            else:
                print("   âš ï¸  åŠ é€Ÿæ•ˆæœæœ‰é™")
        else:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {benchmark_results['error']}")
        print()


def example_3_hybrid_computing():
    """ç¤ºä¾‹3: ç›´æ¥ä½¿ç”¨å¼‚æ„è®¡ç®—å™¨ (é«˜çº§ç”¨æ³•)"""
    print("=== ç¤ºä¾‹3: ç›´æ¥å¼‚æ„è®¡ç®— ===\n")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„æ‰°åŠ¨æ•ˆåº”æ•°æ® 
    n_perts, n_genes = 100, 15000
    print(f"ç”Ÿæˆ {n_perts} æ‰°åŠ¨ Ã— {n_genes} åŸºå› çš„æ•ˆåº”çŸ©é˜µ...")
    
    real_effects = np.random.randn(n_perts, n_genes).astype(np.float32)
    pred_effects = real_effects + np.random.randn(n_perts, n_genes).astype(np.float32) * 0.1
    pert_names = np.array([f"PERT_{i:03d}" for i in range(n_perts)])
    
    # åˆ›å»ºå¼‚æ„è®¡ç®—å™¨
    hybrid_evaluator = HybridVCCEvaluator(
        gpu_device='cuda',
        enable_gpu=True,
        fallback_to_cpu=True
    )
    
    print("å¼‚æ„è®¡ç®—ç³»ç»Ÿä¿¡æ¯:")
    sys_info = hybrid_evaluator.get_system_info()
    for key, value in sys_info.items():
        print(f"   {key}: {value}")
    print()
    
    # æ‰§è¡Œå¼‚æ„è®¡ç®—
    print("æ‰§è¡Œå¼‚æ„è®¡ç®— (GPU: MAE+Discrimination, CPU: Overlap)...")
    start_time = time.time()
    
    individual, aggregated = hybrid_evaluator.compute_vcc_metrics(
        real_effects=real_effects,
        pred_effects=pred_effects,
        perturbation_names=pert_names,
        de_real=None,  # è¿™é‡Œç®€åŒ–ï¼Œå®é™…ä½¿ç”¨æ—¶ä¼ å…¥DEæ•°æ®
        de_pred=None
    )
    
    compute_time = time.time() - start_time
    print(f"è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {compute_time:.3f}ç§’\n")
    
    # æ˜¾ç¤ºç»“æœ
    print("VCCæŒ‡æ ‡ç»“æœ:")
    for metric, scores in individual.items():
        if isinstance(scores, dict) and not metric.startswith('_'):
            avg_score = np.mean(list(scores.values()))
            print(f"   {metric}: {avg_score:.4f} (å¹³å‡)")
    
    if 'vcc_final_score' in aggregated:
        print(f"   VCCæœ€ç»ˆåˆ†æ•°: {aggregated['vcc_final_score']:.4f}")
    
    # è®¡ç®—æ€§èƒ½ç»Ÿè®¡
    if '_computation_stats' in aggregated:
        stats = aggregated['_computation_stats']
        print(f"\nè®¡ç®—æ—¶é—´åˆ†è§£:")
        for component, time_taken in stats.items():
            print(f"   {component}: {time_taken:.3f}ç§’")
    print()


def example_4_production_workflow():
    """ç¤ºä¾‹4: ç”Ÿäº§ç¯å¢ƒå·¥ä½œæµç¨‹"""
    print("=== ç¤ºä¾‹4: ç”Ÿäº§ç¯å¢ƒä½¿ç”¨æµç¨‹ ===\n")
    
    # æ¨¡æ‹ŸçœŸå®VCCåœºæ™¯
    print("æ¨¡æ‹ŸVCCæ¯”èµ›åœºæ™¯...")
    
    # 1. åˆ›å»ºè®­ç»ƒæ•°æ® (baseline)
    print("1. åˆ›å»ºè®­ç»ƒæ•°æ®...")
    train_data = build_random_anndata(
        n_cells=5000, n_genes=20000, n_perts=150,
        pert_col="target", control_var="non-targeting"
    )
    
    # 2. åˆ›å»ºé¢„æµ‹æ•°æ® (æ‚¨çš„æ¨¡å‹è¾“å‡º)
    print("2. å‡†å¤‡æ¨¡å‹é¢„æµ‹æ•°æ®...")  
    pred_data = build_random_anndata(
        n_cells=5000, n_genes=20000, n_perts=150,
        pert_col="target", control_var="non-targeting"
    )
    
    # 3. è®¾ç½®åŠ é€Ÿè¯„ä¼°å™¨
    print("3. åˆå§‹åŒ–GPUåŠ é€Ÿè¯„ä¼°å™¨...")
    evaluator = AcceleratedMetricsEvaluator(
        adata_pred=pred_data,
        adata_real=train_data,  # ä½œä¸ºground truth
        control_pert="non-targeting",
        pert_col="target",
        enable_gpu_acceleration=True,
        fallback_to_cpu=True  # å®‰å…¨å›é€€
    )
    
    # 4. è®¡ç®—VCCåˆ†æ•°
    print("4. è®¡ç®—VCCè¯„åˆ† (GPUåŠ é€Ÿ)...")
    start_time = time.time()
    
    results, agg_results = evaluator.compute(
        profile="vcc",
        use_gpu_for_vcc=True
    )
    
    evaluation_time = time.time() - start_time
    print(f"   è¯„åˆ†è®¡ç®—å®Œæˆ: {evaluation_time:.2f}ç§’")
    
    # 5. åˆ†æç»“æœ
    print("5. åˆ†æè¯„åˆ†ç»“æœ:")
    print(f"   ä¸ªä½“ç»“æœç»´åº¦: {results.shape}")
    print(f"   èšåˆç»“æœç»´åº¦: {agg_results.shape}")
    
    # æå–å…³é”®æŒ‡æ ‡
    if hasattr(agg_results, 'filter'):  # Polars DataFrame
        try:
            vcc_metrics = ["mae", "discrimination_score_l1", "overlap_at_N"]
            for metric in vcc_metrics:
                if metric in agg_results.columns:
                    mean_row = agg_results.filter(pl.col("statistic") == "mean")
                    if len(mean_row) > 0:
                        score = mean_row[metric][0]
                        print(f"   {metric}: {score:.4f}")
        except:
            pass
    
    # 6. ä¿å­˜ç»“æœ (å¯é€‰)
    print("6. ä¿å­˜ç»“æœ...")
    results.write_csv("vcc_detailed_results.csv")
    agg_results.write_csv("vcc_aggregated_results.csv") 
    print("   ç»“æœå·²ä¿å­˜åˆ°CSVæ–‡ä»¶")
    
    print("\nğŸ‰ VCCè¯„åˆ†æµç¨‹å®Œæˆ!")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("VCC GPUåŠ é€Ÿæ¨¡å—ä½¿ç”¨ç¤ºä¾‹\n")
    print("="*50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    print("="*50 + "\n")
    
    try:
        # è¿è¡Œç¤ºä¾‹
        example_1_basic_usage()
        example_2_benchmark()
        example_3_hybrid_computing()
        example_4_production_workflow()
        
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ç¯å¢ƒé…ç½®å’Œä¾èµ–åŒ…å®‰è£…")


if __name__ == "__main__":
    main()